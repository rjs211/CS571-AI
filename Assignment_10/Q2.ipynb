{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "random.seed(11)\n",
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Conv1D, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence(sentence):\n",
    "    '''\n",
    "    Function for parsing the words and tags from the\n",
    "    sentences of the input corpus.\n",
    "    '''\n",
    "    word_tag_pairs = sentence.split(\" \")\n",
    "    words = []\n",
    "    tags = []\n",
    "\n",
    "    for i, word_tag in enumerate(word_tag_pairs):\n",
    "        word, tag = word_tag.strip().rsplit('/', 1)\n",
    "        words.append(word)\n",
    "        tags.append(tag)\n",
    "        \n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the sentences into a list.\n",
    "parsed_sentences = []\n",
    "\n",
    "with open('./Brown_train.txt', 'r') as file:\n",
    "    sentences = file.readlines()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        parsed_sentences.append(parse_sentence(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(X_train, Y_train):\n",
    "    '''\n",
    "    Function for building the vocabulary from the training set of\n",
    "    words and tags.\n",
    "    '''\n",
    "    vocabulary2id = dict()    \n",
    "    tag2id = dict()\n",
    "    vocabulary2id['UNK'] = 0\n",
    "    vocabulary2id['PAD'] = 1\n",
    "\n",
    "    for sent in X_train:\n",
    "        for word in sent:\n",
    "            if word not in vocabulary2id.keys():\n",
    "                vocabulary2id[word] = len(vocabulary2id)\n",
    "    \n",
    "    tag2id['PAD'] = 0\n",
    "    for sent in Y_train:\n",
    "        for tag in sent:\n",
    "            if tag not in tag2id.keys():\n",
    "                tag2id[tag] = len(tag2id)\n",
    "    \n",
    "    return vocabulary2id, tag2id\n",
    "\n",
    "def get_word_tag_counts(X_train, Y_train, vocabulary2id, tag2id):\n",
    "    '''\n",
    "    Function for calculating the counts pertaining to the\n",
    "    individual word tags.\n",
    "    '''\n",
    "    wordcount = defaultdict(int)\n",
    "    tagcount = defaultdict(int)\n",
    "    tagpaircount = defaultdict(int)\n",
    "    tagtriplecount = defaultdict(int)\n",
    "    \n",
    "    for sent in X_train:\n",
    "        for word in sent:\n",
    "            wordcount[word] += 1\n",
    "    \n",
    "    for sent in Y_train:\n",
    "        for tag in sent:\n",
    "            tagcount[tag] += 1\n",
    "    \n",
    "    for sent in Y_train:\n",
    "        for i in range(len(sent) - 1):\n",
    "            tagpaircount[sent[i], sent[i + 1]] += 1\n",
    "\n",
    "    for sent in Y_train:\n",
    "        for i in range(len(sent) - 2):\n",
    "            tagtriplecount[sent[i], sent[i + 1], sent[i + 2]] += 1\n",
    "    \n",
    "    return wordcount, tagcount, tagpaircount, tagtriplecount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['At',\n",
       "   'that',\n",
       "   'time',\n",
       "   'highway',\n",
       "   'engineers',\n",
       "   'traveled',\n",
       "   'rough',\n",
       "   'and',\n",
       "   'dirty',\n",
       "   'roads',\n",
       "   'to',\n",
       "   'accomplish',\n",
       "   'their',\n",
       "   'duties',\n",
       "   '.'],\n",
       "  ['ADP',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'VERB',\n",
       "   'ADJ',\n",
       "   'CONJ',\n",
       "   'ADJ',\n",
       "   'NOUN',\n",
       "   'PRT',\n",
       "   'VERB',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   '.']),\n",
       " (['Using',\n",
       "   'privately-owned',\n",
       "   'vehicles',\n",
       "   'was',\n",
       "   'a',\n",
       "   'personal',\n",
       "   'hardship',\n",
       "   'for',\n",
       "   'such',\n",
       "   'employees',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'matter',\n",
       "   'of',\n",
       "   'providing',\n",
       "   'state',\n",
       "   'transportation',\n",
       "   'was',\n",
       "   'felt',\n",
       "   'perfectly',\n",
       "   'justifiable',\n",
       "   '.'],\n",
       "  ['VERB',\n",
       "   'ADJ',\n",
       "   'NOUN',\n",
       "   'VERB',\n",
       "   'DET',\n",
       "   'ADJ',\n",
       "   'NOUN',\n",
       "   'ADP',\n",
       "   'ADJ',\n",
       "   'NOUN',\n",
       "   '.',\n",
       "   'CONJ',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'ADP',\n",
       "   'VERB',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'VERB',\n",
       "   'VERB',\n",
       "   'ADV',\n",
       "   'ADJ',\n",
       "   '.']),\n",
       " (['Once',\n",
       "   'the',\n",
       "   'principle',\n",
       "   'was',\n",
       "   'established',\n",
       "   ',',\n",
       "   'the',\n",
       "   'increase',\n",
       "   'in',\n",
       "   'state-owned',\n",
       "   'vehicles',\n",
       "   'came',\n",
       "   'rapidly',\n",
       "   '.'],\n",
       "  ['ADP',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'VERB',\n",
       "   'VERB',\n",
       "   '.',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'ADP',\n",
       "   'ADJ',\n",
       "   'NOUN',\n",
       "   'VERB',\n",
       "   'ADV',\n",
       "   '.']),\n",
       " (['And',\n",
       "   'reasons',\n",
       "   'other',\n",
       "   'than',\n",
       "   'employee',\n",
       "   'need',\n",
       "   'contributed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'growth',\n",
       "   '.'],\n",
       "  ['CONJ',\n",
       "   'NOUN',\n",
       "   'ADJ',\n",
       "   'ADP',\n",
       "   'NOUN',\n",
       "   'NOUN',\n",
       "   'VERB',\n",
       "   'ADP',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   '.']),\n",
       " (['Table',\n",
       "   '1',\n",
       "   'immediately',\n",
       "   'below',\n",
       "   'shows',\n",
       "   'the',\n",
       "   'rate',\n",
       "   'of',\n",
       "   'growth',\n",
       "   'of',\n",
       "   'vehicles',\n",
       "   'and',\n",
       "   'employees',\n",
       "   '.'],\n",
       "  ['NOUN',\n",
       "   'NUM',\n",
       "   'ADV',\n",
       "   'ADV',\n",
       "   'VERB',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'ADP',\n",
       "   'NOUN',\n",
       "   'ADP',\n",
       "   'NOUN',\n",
       "   'CONJ',\n",
       "   'NOUN',\n",
       "   '.'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the test and training sets of sentences.\n",
    "kf = KFold(n_splits = 3, shuffle = False)\n",
    "parsed_sentences = np.asarray(parsed_sentences)\n",
    "scores = []\n",
    "scores1 = []\n",
    "y_pred_idx = []\n",
    "y_pred_idx1 = []\n",
    "y_test_idx = []\n",
    "y_test_idx1 = []\n",
    "\n",
    "preds = []\n",
    "\n",
    "for train_index, test_index in kf.split(parsed_sentences):\n",
    "    train_data = parsed_sentences[train_index]\n",
    "    test_data = parsed_sentences[test_index]\n",
    "    X_train = [a[0] for a in train_data]\n",
    "    Y_train = [a[1] for a in train_data]\n",
    "    X_test = [a[0] for a in test_data]\n",
    "    Y_test = [a[1] for a in test_data]\n",
    "    \n",
    "    # Build the vocabulary and word counts.\n",
    "    vocabulary2id, tag2id = get_vocab(X_train, Y_train)\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "padlen = max(len(i) for i in X_train)\n",
    "def pad(sentence, padid=vocabulary2id['PAD']):\n",
    "    out = sentence[:padlen]\n",
    "    padding = [padid for _ in range(padlen - len(out))]\n",
    "    return out + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ids = np.asarray([pad([vocabulary2id[word] if word in vocabulary2id.keys() else vocabulary2id['UNK'] for word in sent]) for sent in X_train])\n",
    "X_test_ids = np.array([pad([vocabulary2id[word] if word in vocabulary2id.keys() else vocabulary2id['UNK'] for word in sent]) for sent in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_ids = np.asarray([pad([tag2id[word] if word in tag2id.keys() else tag2id['UNK'] for word in sent], tag2id['PAD']) for sent in Y_train])\n",
    "Y_test_ids = np.asarray([pad([tag2id[word] if word in tag2id.keys() else tag2id['UNK'] for word in sent], tag2id['PAD']) for sent in Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2onehot(Y, numtags):\n",
    "    out = []\n",
    "    for s in Y:\n",
    "        categories = []\n",
    "        for item in s:\n",
    "            categories.append(np.zeros(numtags))\n",
    "            categories[-1][item] = 1.0\n",
    "        out.append(categories)\n",
    "    return np.array(out)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_onehot = id2onehot(Y_train_ids, len(tag2id))\n",
    "Y_test_onehot = id2onehot(Y_test_ids, len(tag2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 172, 100)          2211500   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 172, 384)          112512    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 172, 13)           5005      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 172, 13)           0         \n",
      "=================================================================\n",
      "Total params: 2,329,017\n",
      "Trainable params: 2,329,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(padlen, )))\n",
    "model.add(Embedding(len(vocabulary2id), 100))\n",
    "model.add(Bidirectional(SimpleRNN(int((128+256)/2), return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2id))))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14661 samples, validate on 3666 samples\n",
      "Epoch 1/5\n",
      "14661/14661 [==============================] - 90s 6ms/step - loss: 0.3566 - accuracy: 0.9029 - val_loss: 0.2084 - val_accuracy: 0.9245\n",
      "Epoch 2/5\n",
      "14661/14661 [==============================] - 89s 6ms/step - loss: 0.1755 - accuracy: 0.9434 - val_loss: 0.1628 - val_accuracy: 0.9543\n",
      "Epoch 3/5\n",
      "14661/14661 [==============================] - 89s 6ms/step - loss: 0.1086 - accuracy: 0.9736 - val_loss: 0.0801 - val_accuracy: 0.9806\n",
      "Epoch 4/5\n",
      "14661/14661 [==============================] - 90s 6ms/step - loss: 0.0460 - accuracy: 0.9906 - val_loss: 0.0423 - val_accuracy: 0.9907\n",
      "Epoch 5/5\n",
      "14661/14661 [==============================] - 88s 6ms/step - loss: 0.0224 - accuracy: 0.9958 - val_loss: 0.0298 - val_accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4c286dd6d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_ids, Y_train_onehot, batch_size=128, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8796389249699855\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = np.sum((Y_test_ids == np.argmax(predictions, axis=-1)) * (Y_test_ids != 0)) / np.sum((Y_test_ids != 0))\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_argmax = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nopad = []\n",
    "y_true_nopad = []\n",
    "\n",
    "for i in range(len(Y_test_ids)):\n",
    "    for j in range(len(Y_test_ids[i])):\n",
    "        if Y_test_ids[i][j] != 0 and predictions_argmax[i][j] != 0:\n",
    "            y_true_nopad.append(Y_test_ids[i][j])\n",
    "            if predictions_argmax[i][j] == 0:\n",
    "                y_pred_nopad.append(1)\n",
    "            else:\n",
    "                y_pred_nopad.append(predictions_argmax[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nopad = np.asarray(y_pred_nopad)\n",
    "y_true_nopad = np.asarray(y_true_nopad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8796929935992526"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_nopad == y_true_nopad).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prec, rec, fscore, _ = precision_recall_fscore_support(y_true_nopad, y_pred_nopad, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8813291814812507, 0.8796929935992526, 0.8715809429532625)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec, rec, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 172, 100)          2211500   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 172, 384)          112512    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 172, 13)           5005      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 172, 13)           0         \n",
      "=================================================================\n",
      "Total params: 2,329,017\n",
      "Trainable params: 2,329,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(padlen, )))\n",
    "model.add(Embedding(len(vocabulary2id), 100))\n",
    "model.add(Bidirectional(SimpleRNN(int((128+256)/2), return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2id))))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.003),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14661 samples, validate on 3666 samples\n",
      "Epoch 1/4\n",
      "14661/14661 [==============================] - 93s 6ms/step - loss: 0.3103 - accuracy: 0.9255 - val_loss: 0.1091 - val_accuracy: 0.9713\n",
      "Epoch 2/4\n",
      "14661/14661 [==============================] - 88s 6ms/step - loss: 0.0468 - accuracy: 0.9884 - val_loss: 0.0268 - val_accuracy: 0.9931\n",
      "Epoch 3/4\n",
      "14661/14661 [==============================] - 92s 6ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.0187 - val_accuracy: 0.9945\n",
      "Epoch 4/4\n",
      "14661/14661 [==============================] - 89s 6ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0171 - val_accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4b147c9208>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_ids, Y_train_onehot, batch_size=128, epochs=4, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9051051223319907\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = np.sum((Y_test_ids == np.argmax(predictions, axis=-1)) * (Y_test_ids != 0)) / np.sum((Y_test_ids != 0))\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_argmax = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nopad = []\n",
    "y_true_nopad = []\n",
    "\n",
    "for i in range(len(Y_test_ids)):\n",
    "    for j in range(len(Y_test_ids[i])):\n",
    "        if Y_test_ids[i][j] != 0 and predictions_argmax[i][j] != 0:\n",
    "            y_true_nopad.append(Y_test_ids[i][j])\n",
    "            if predictions_argmax[i][j] == 0:\n",
    "                y_pred_nopad.append(1)\n",
    "            else:\n",
    "                y_pred_nopad.append(predictions_argmax[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nopad = np.asarray(y_pred_nopad)\n",
    "y_true_nopad = np.asarray(y_true_nopad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9053796495542576"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_nopad == y_true_nopad).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prec, rec, fscore, _ = precision_recall_fscore_support(y_true_nopad, y_pred_nopad, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.906992363947336, 0.9053796495542576, 0.9024334357862384)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec, rec, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      8039\n",
      "           2       0.87      0.82      0.84     10635\n",
      "           3       1.00      1.00      1.00     26236\n",
      "           4       0.87      0.90      0.88      4667\n",
      "           5       0.87      0.90      0.89     35919\n",
      "           6       0.85      0.91      0.88     63554\n",
      "           7       0.96      0.96      0.96     35048\n",
      "           8       0.98      0.99      0.99     29546\n",
      "           9       0.88      0.69      0.77     20469\n",
      "          10       0.70      0.96      0.81      4858\n",
      "          11       0.96      0.43      0.60      4712\n",
      "          12       0.00      0.00      0.00       292\n",
      "\n",
      "    accuracy                           0.91    243975\n",
      "   macro avg       0.83      0.80      0.80    243975\n",
      "weighted avg       0.91      0.91      0.90    243975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_nopad, y_pred_nopad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAD': 0,\n",
       " 'CONJ': 1,\n",
       " 'ADV': 2,\n",
       " '.': 3,\n",
       " 'PRT': 4,\n",
       " 'VERB': 5,\n",
       " 'NOUN': 6,\n",
       " 'ADP': 7,\n",
       " 'DET': 8,\n",
       " 'ADJ': 9,\n",
       " 'PRON': 10,\n",
       " 'NUM': 11,\n",
       " 'X': 12}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
