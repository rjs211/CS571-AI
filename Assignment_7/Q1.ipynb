{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, random\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shikhar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_sentiment_shuffled.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "    data = [re.sub(r'([^\\w\\s]|[0-9])', ' ', line) for line in data]\n",
    "    data = [re.sub(r'(\\s+)', ' ', line) for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = [(line2[0], line2[1], line2[2], line2[3:]) for line2 in [line1.strip().split() for line1 in data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [line[3] for line in split_data]\n",
    "Y = [line[1] for line in split_data]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('')\n",
    "\n",
    "X = [[w for w in words if w not in stop_words] for words in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bought', 'album', 'loved', 'title', 'song', 'great', 'song', 'bad', 'rest', 'album', 'right', 'well', 'rest', 'songs', 'filler', 'n', 'worth', 'money', 'paid', 'either', 'shameless', 'bubblegum', 'oversentimentalized', 'depressing', 'tripe', 'kenny', 'chesney', 'popular', 'artist', 'result', 'cookie', 'cutter', 'category', 'nashville', 'music', 'scene', 'gotta', 'pump', 'albums', 'record', 'company', 'keep', 'lining', 'pockets', 'suckers', 'keep', 'buying', 'garbage', 'perpetuate', 'garbage', 'coming', 'town', 'get', 'soapbox', 'country', 'music', 'really', 'needs', 'get', 'back', 'roots', 'stop', 'pop', 'nonsense', 'country', 'music', 'really', 'considered', 'mainstream', 'two', 'different', 'things'], ['misled', 'thought', 'buying', 'entire', 'cd', 'contains', 'one', 'song'], ['introduced', 'many', 'ell', 'high', 'school', 'students', 'lois', 'lowery', 'depth', 'characters', 'brilliant', 'writer', 'capable', 'inspiring', 'fierce', 'passion', 'readers', 'encounter', 'shocking', 'details', 'utopian', 'worlds', 'anxious', 'read', 'companion', 'novel', 'planned', 'share', 'class', 'january', 'although', 'series', 'written', 'th', 'graders', 'older', 'book', 'simplicity', 'message', 'language', 'writing', 'style', 'inspire', 'one', 'sadly', 'disappointed'], ['anything', 'purchase', 'left', 'behind', 'series', 'excellent', 'read', 'books', 'great', 'close', 'bible', 'entire', 'set', 'amazon', 'great', 'shopping', 'site', 'ship', 'fast', 'would', 'recommend', 'christian', 'wanting', 'know', 'expect', 'return', 'christ', 'fiction', 'still', 'makes', 'good', 'point'], ['loved', 'movies', 'cant', 'wiat', 'third', 'one', 'funny', 'suitable', 'chilren']]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(XData):\n",
    "    vocab = set()\n",
    "\n",
    "    for line in XData:\n",
    "        for word in line:\n",
    "            vocab.add(word)\n",
    "            \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainNaiveBayes(XTrain, YTrain, alpha=1):\n",
    "    prior = {}\n",
    "    vocabulary = get_vocab(XTrain)\n",
    "    prob_word_given_class = {}\n",
    "    classes = set(YTrain)\n",
    "\n",
    "    for c in classes:\n",
    "        prior[c] = np.log(len([y for y in YTrain if y == c]) / len(YTrain))\n",
    "        class_documents = [doc for doc, label in zip(XTrain, YTrain) if label == c]\n",
    "        total_word_count = sum([len(doc) for doc in class_documents])\n",
    "        prob_word_given_class[c] = {}\n",
    "        for word in vocabulary:\n",
    "            word_occurences = 0\n",
    "            for doc in class_documents:\n",
    "                word_occurences += len([w for w in doc if w == word])\n",
    "            prob_word_given_class[c][word] = np.log((word_occurences + alpha) / (total_word_count + alpha * len(vocabulary)))\n",
    "    \n",
    "    return prior, prob_word_given_class, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'pos': -1.0986122886681098, 'neg': -0.40546510810816444},\n",
       " {'pos': {'older': -4.727387818712341,\n",
       "   'good': -4.034240638152395,\n",
       "   'depth': -4.727387818712341,\n",
       "   'cd': -4.727387818712341,\n",
       "   'one': -4.727387818712341,\n",
       "   'characters': -4.727387818712341,\n",
       "   'graders': -4.727387818712341,\n",
       "   'return': -4.034240638152395,\n",
       "   'thought': -4.727387818712341,\n",
       "   'introduced': -4.727387818712341,\n",
       "   'language': -4.727387818712341,\n",
       "   'worlds': -4.727387818712341,\n",
       "   'shocking': -4.727387818712341,\n",
       "   'passion': -4.727387818712341,\n",
       "   'sadly': -4.727387818712341,\n",
       "   'th': -4.727387818712341,\n",
       "   'bible': -4.034240638152395,\n",
       "   'great': -3.628775530044231,\n",
       "   'message': -4.727387818712341,\n",
       "   'fast': -4.034240638152395,\n",
       "   'utopian': -4.727387818712341,\n",
       "   'still': -4.034240638152395,\n",
       "   'site': -4.034240638152395,\n",
       "   'fiction': -4.034240638152395,\n",
       "   'inspiring': -4.727387818712341,\n",
       "   'class': -4.727387818712341,\n",
       "   'writer': -4.727387818712341,\n",
       "   'christ': -4.034240638152395,\n",
       "   'anxious': -4.727387818712341,\n",
       "   'shopping': -4.034240638152395,\n",
       "   'many': -4.727387818712341,\n",
       "   'excellent': -4.034240638152395,\n",
       "   'book': -4.727387818712341,\n",
       "   'recommend': -4.034240638152395,\n",
       "   'expect': -4.034240638152395,\n",
       "   'readers': -4.727387818712341,\n",
       "   'share': -4.727387818712341,\n",
       "   'makes': -4.034240638152395,\n",
       "   'ell': -4.727387818712341,\n",
       "   'set': -4.034240638152395,\n",
       "   'lois': -4.727387818712341,\n",
       "   'brilliant': -4.727387818712341,\n",
       "   'students': -4.727387818712341,\n",
       "   'style': -4.727387818712341,\n",
       "   'would': -4.034240638152395,\n",
       "   'buying': -4.727387818712341,\n",
       "   'disappointed': -4.727387818712341,\n",
       "   'although': -4.727387818712341,\n",
       "   'encounter': -4.727387818712341,\n",
       "   'january': -4.727387818712341,\n",
       "   'left': -4.034240638152395,\n",
       "   'ship': -4.034240638152395,\n",
       "   'writing': -4.727387818712341,\n",
       "   'capable': -4.727387818712341,\n",
       "   'christian': -4.034240638152395,\n",
       "   'inspire': -4.727387818712341,\n",
       "   'details': -4.727387818712341,\n",
       "   'contains': -4.727387818712341,\n",
       "   'simplicity': -4.727387818712341,\n",
       "   'anything': -4.034240638152395,\n",
       "   'song': -4.727387818712341,\n",
       "   'companion': -4.727387818712341,\n",
       "   'entire': -4.034240638152395,\n",
       "   'wanting': -4.034240638152395,\n",
       "   'amazon': -4.034240638152395,\n",
       "   'series': -4.034240638152395,\n",
       "   'close': -4.034240638152395,\n",
       "   'know': -4.034240638152395,\n",
       "   'planned': -4.727387818712341,\n",
       "   'books': -4.034240638152395,\n",
       "   'purchase': -4.034240638152395,\n",
       "   'behind': -4.034240638152395,\n",
       "   'misled': -4.727387818712341,\n",
       "   'high': -4.727387818712341,\n",
       "   'novel': -4.727387818712341,\n",
       "   'school': -4.727387818712341,\n",
       "   'written': -4.727387818712341,\n",
       "   'point': -4.034240638152395,\n",
       "   'lowery': -4.727387818712341,\n",
       "   'fierce': -4.727387818712341,\n",
       "   'read': -4.034240638152395},\n",
       "  'neg': {'older': -4.212127597878484,\n",
       "   'good': -4.90527477843843,\n",
       "   'depth': -4.212127597878484,\n",
       "   'cd': -4.212127597878484,\n",
       "   'one': -3.8066624897703196,\n",
       "   'characters': -4.212127597878484,\n",
       "   'graders': -4.212127597878484,\n",
       "   'return': -4.90527477843843,\n",
       "   'thought': -4.212127597878484,\n",
       "   'introduced': -4.212127597878484,\n",
       "   'language': -4.212127597878484,\n",
       "   'worlds': -4.212127597878484,\n",
       "   'shocking': -4.212127597878484,\n",
       "   'passion': -4.212127597878484,\n",
       "   'sadly': -4.212127597878484,\n",
       "   'th': -4.212127597878484,\n",
       "   'bible': -4.90527477843843,\n",
       "   'great': -4.90527477843843,\n",
       "   'message': -4.212127597878484,\n",
       "   'fast': -4.90527477843843,\n",
       "   'utopian': -4.212127597878484,\n",
       "   'still': -4.90527477843843,\n",
       "   'site': -4.90527477843843,\n",
       "   'fiction': -4.90527477843843,\n",
       "   'inspiring': -4.212127597878484,\n",
       "   'class': -4.212127597878484,\n",
       "   'writer': -4.212127597878484,\n",
       "   'christ': -4.90527477843843,\n",
       "   'anxious': -4.212127597878484,\n",
       "   'shopping': -4.90527477843843,\n",
       "   'many': -4.212127597878484,\n",
       "   'excellent': -4.90527477843843,\n",
       "   'book': -4.212127597878484,\n",
       "   'recommend': -4.90527477843843,\n",
       "   'expect': -4.90527477843843,\n",
       "   'readers': -4.212127597878484,\n",
       "   'share': -4.212127597878484,\n",
       "   'makes': -4.90527477843843,\n",
       "   'ell': -4.212127597878484,\n",
       "   'set': -4.90527477843843,\n",
       "   'lois': -4.212127597878484,\n",
       "   'brilliant': -4.212127597878484,\n",
       "   'students': -4.212127597878484,\n",
       "   'style': -4.212127597878484,\n",
       "   'would': -4.90527477843843,\n",
       "   'buying': -4.212127597878484,\n",
       "   'disappointed': -4.212127597878484,\n",
       "   'although': -4.212127597878484,\n",
       "   'encounter': -4.212127597878484,\n",
       "   'january': -4.212127597878484,\n",
       "   'left': -4.90527477843843,\n",
       "   'ship': -4.90527477843843,\n",
       "   'writing': -4.212127597878484,\n",
       "   'capable': -4.212127597878484,\n",
       "   'christian': -4.90527477843843,\n",
       "   'inspire': -4.212127597878484,\n",
       "   'details': -4.212127597878484,\n",
       "   'contains': -4.212127597878484,\n",
       "   'simplicity': -4.212127597878484,\n",
       "   'anything': -4.90527477843843,\n",
       "   'song': -4.212127597878484,\n",
       "   'companion': -4.212127597878484,\n",
       "   'entire': -4.212127597878484,\n",
       "   'wanting': -4.90527477843843,\n",
       "   'amazon': -4.90527477843843,\n",
       "   'series': -4.212127597878484,\n",
       "   'close': -4.90527477843843,\n",
       "   'know': -4.90527477843843,\n",
       "   'planned': -4.212127597878484,\n",
       "   'books': -4.90527477843843,\n",
       "   'purchase': -4.90527477843843,\n",
       "   'behind': -4.90527477843843,\n",
       "   'misled': -4.212127597878484,\n",
       "   'high': -4.212127597878484,\n",
       "   'novel': -4.212127597878484,\n",
       "   'school': -4.212127597878484,\n",
       "   'written': -4.212127597878484,\n",
       "   'point': -4.90527477843843,\n",
       "   'lowery': -4.212127597878484,\n",
       "   'fierce': -4.212127597878484,\n",
       "   'read': -4.212127597878484}},\n",
       " {'although',\n",
       "  'amazon',\n",
       "  'anxious',\n",
       "  'anything',\n",
       "  'behind',\n",
       "  'bible',\n",
       "  'book',\n",
       "  'books',\n",
       "  'brilliant',\n",
       "  'buying',\n",
       "  'capable',\n",
       "  'cd',\n",
       "  'characters',\n",
       "  'christ',\n",
       "  'christian',\n",
       "  'class',\n",
       "  'close',\n",
       "  'companion',\n",
       "  'contains',\n",
       "  'depth',\n",
       "  'details',\n",
       "  'disappointed',\n",
       "  'ell',\n",
       "  'encounter',\n",
       "  'entire',\n",
       "  'excellent',\n",
       "  'expect',\n",
       "  'fast',\n",
       "  'fiction',\n",
       "  'fierce',\n",
       "  'good',\n",
       "  'graders',\n",
       "  'great',\n",
       "  'high',\n",
       "  'inspire',\n",
       "  'inspiring',\n",
       "  'introduced',\n",
       "  'january',\n",
       "  'know',\n",
       "  'language',\n",
       "  'left',\n",
       "  'lois',\n",
       "  'lowery',\n",
       "  'makes',\n",
       "  'many',\n",
       "  'message',\n",
       "  'misled',\n",
       "  'novel',\n",
       "  'older',\n",
       "  'one',\n",
       "  'passion',\n",
       "  'planned',\n",
       "  'point',\n",
       "  'purchase',\n",
       "  'read',\n",
       "  'readers',\n",
       "  'recommend',\n",
       "  'return',\n",
       "  'sadly',\n",
       "  'school',\n",
       "  'series',\n",
       "  'set',\n",
       "  'share',\n",
       "  'ship',\n",
       "  'shocking',\n",
       "  'shopping',\n",
       "  'simplicity',\n",
       "  'site',\n",
       "  'song',\n",
       "  'still',\n",
       "  'students',\n",
       "  'style',\n",
       "  'th',\n",
       "  'thought',\n",
       "  'utopian',\n",
       "  'wanting',\n",
       "  'worlds',\n",
       "  'would',\n",
       "  'writer',\n",
       "  'writing',\n",
       "  'written'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainNaiveBayes(X[1:4], Y[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredNaiveBayes(XTest, prior, prob_word_given_class, vocabulary):\n",
    "    pred_labels = []\n",
    "    \n",
    "    for line in XTest:\n",
    "        posterior = {}\n",
    "        max_line = -float('inf')\n",
    "        argmax_line = None\n",
    "\n",
    "        for c in prior.keys():\n",
    "            posterior[c] = prior[c]    \n",
    "            \n",
    "            for word in line:\n",
    "                if word in vocabulary:\n",
    "                    posterior[c] += prob_word_given_class[c][word]\n",
    "\n",
    "            if max_line < posterior[c]:\n",
    "                max_line = posterior[c]\n",
    "                argmax_line = c\n",
    "        \n",
    "        pred_labels.append(argmax_line)\n",
    "    \n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(ytrue, ypred):\n",
    "    POS_CLASS, NEG_CLASS = 'pos', 'neg'\n",
    "    true_positives = len([1 for a, b in zip(ytrue, ypred) if ytrue == POS_CLASS and ypred == POS_CLASS])\n",
    "    false_positives = len([1 for a, b in zip(ytrue, ypred) if ytrue == NEG_CLASS and ypred == POS_CLASS])\n",
    "    true_negatives = len([1 for a, b in zip(ytrue, ypred) if ytrue == NEG_CLASS and ypred == NEG_CLASS])\n",
    "    false_negatives = len([1 for a, b in zip(ytrue, ypred) if ytrue == POS_CLASS and ypred == NEG_CLASS])\n",
    "    \n",
    "    acc = (true_positives + true_negatives) / len(ytrue)\n",
    "    if (true_positives + false_positives) != 0:\n",
    "        prec = (true_positives) / (true_positives + false_positives)\n",
    "    else:\n",
    "        prec = float('nan')\n",
    "    if (true_positives + false_negatives) != 0:\n",
    "        rec = (true_positives) / (true_positives + false_negatives)\n",
    "    else:\n",
    "        rec = float('nan')\n",
    "    if (prec + rec) != 0:\n",
    "        f1 = 2. * prec * rec / (prec + rec)\n",
    "    else:\n",
    "        f1 = float('nan')\n",
    "    \n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainTestNaiveBayes(XTrain, YTrain, XTest, YTest):\n",
    "    prior, prob_word_given_class, vocabulary = TrainNaiveBayes(XTrain, YTrain)\n",
    "    YPred = PredNaiveBayes(XTest, prior, prob_word_given_class, vocabulary)\n",
    "    return get_scores(YTest, YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(X, Y))\n",
    "random.shuffle(data)\n",
    "X, Y = [d[0] for d in data], [d[1] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "split_size = round(len(X) / num_folds + 0.5)\n",
    "X_splits = []\n",
    "Y_splits = []\n",
    "for i in range(num_folds):\n",
    "    X_splits.append(X[i * split_size: (i + 1) * split_size])\n",
    "    Y_splits.append(Y[i * split_size: (i + 1) * split_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2383, 2383)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_splits[0]), len(Y_splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    XTrain = copy(X_splits)\n",
    "    del XTrain[fold]\n",
    "    XTrain = sum(XTrain, [])\n",
    "    XTest = X_splits[fold]\n",
    "\n",
    "    YTrain = copy(Y_splits)\n",
    "    del YTrain[fold]\n",
    "    YTrain = sum(YTrain, [])\n",
    "    YTest = Y_splits[fold]\n",
    "    scores = TrainTestNaiveBayes(XTrain, YTrain, XTest, YTest)\n",
    "    print('Acc: {} Prec: {}, Rec: {}, F1: {}'.format(*scores))\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
