{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, random\n",
    "from copy import copy, deepcopy\n",
    "import sys\n",
    "from collections import Counter\n",
    "import queue\n",
    "from scipy import stats\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('tagsets')\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import FreqDist\n",
    "from nltk import ngrams\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_labe(data):\n",
    "    text = []\n",
    "    answer_type = []\n",
    "    label = []\n",
    "    sent_length = []\n",
    "    for line in data:\n",
    "        a = line.split(':', maxsplit=1)\n",
    "        label.append(a[0])\n",
    "        b = a[1].strip().split(' ',maxsplit=1)\n",
    "        text.append(b[1].lower())\n",
    "        answer_type.append(b[0])\n",
    "    # remove punctuations\n",
    "    clean_text = [re.sub(r'([^\\w\\s]|[0-9])', ' ', line) for line in text]\n",
    "    clean_text = [re.sub(r'(\\s+)', ' ', line) for line in clean_text]\n",
    "    return clean_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add('')\n",
    "    text_tokens = [sent.split() for sent in text]\n",
    "    text_no_stopwords = [[w for w in words if w not in stop_words] for words in text_tokens]\n",
    "    return text_no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_topk(token_list, n, k, feat_dicts=None):\n",
    "    ngrams_list = [list(ngrams(sent, n)) for sent in token_list]\n",
    "    if feat_dicts:\n",
    "        ngrams_topk_dict, idx2ngram_dict = feat_dicts\n",
    "    else:\n",
    "        all_ngrams = sum(ngrams_list, [])\n",
    "        freq_dist = FreqDist(all_ngrams)\n",
    "        freq_dist_k = freq_dist.most_common(k)\n",
    "        ngrams_topk_list =  [ngram_token for ngram_token, _ in freq_dist_k]\n",
    "        ngrams_topk_dict = {ngram_token:i for i, ngram_token in enumerate(ngrams_topk_list)}\n",
    "        idx2ngram_dict = {v: k for k, v in ngrams_topk_dict.items()}\n",
    "    \n",
    "    ngrams_freq_feat = []\n",
    "    for ngram_tokens in ngrams_list:\n",
    "        ngram_token_freq = np.zeros(k, dtype = np.int32)\n",
    "        for ngram_token in ngram_tokens:\n",
    "            if ngram_token in ngrams_topk_dict.keys():\n",
    "                ngram_token_freq[ ngrams_topk_dict[ngram_token] ]+=1\n",
    "        ngrams_freq_feat.append(ngram_token_freq)\n",
    "    \n",
    "    return np.asarray(ngrams_freq_feat, dtype = np.int32), ngrams_topk_dict, idx2ngram_dict, ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file line by line and clean the text of punctuation.\n",
    "with open('Data/train_5500.label', 'r',encoding='latin-1') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "X_train, Y_train = get_text_labe(data)\n",
    "\n",
    "with open('./Data/TREC_10.label', 'r',encoding='latin-1') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "X_test, Y_test = get_text_labe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "get vocab. (top 500)\n",
    "\n",
    "get sentence length feature (1)\n",
    "get lexical features: \n",
    "presence of n grams (1000)\n",
    "        1-gram (500)\n",
    "        2-gram (300)\n",
    "        3-gram (200)\n",
    "        \n",
    "Use nltk pos tagger and get tags\n",
    "for bag of tags model, assign presence to 1 iff the word is in 500 vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_train(X_train, feats_to_use = ('len', 'uni' ,'bi' ,'tri' ,'pos')):\n",
    "    X_train = [sent.split() for sent in X_train]\n",
    "    features = []\n",
    "    feat_dicts_list = []\n",
    "\n",
    "    if 'len' in feats_to_use:\n",
    "        X_train_sentlen = np.reshape(np.asarray([len(sent) for sent in X_train], dtype = np.int32),(-1,1))\n",
    "        feat_dicts_list.append(None)\n",
    "    else:\n",
    "        X_train_sentlen = np.reshape(np.asarray([-1 for sent in X_train], dtype = np.int32),(-1,1))\n",
    "    features.append(X_train_sentlen)\n",
    "    \n",
    "    if 'uni' in feats_to_use:\n",
    "        X_train_unigram = ngram_topk(X_train, 1, 500)\n",
    "        features.append(X_train_unigram[0])\n",
    "        feat_dicts_list.append(X_train_unigram[1:-1])\n",
    "    if 'bi' in feats_to_use:\n",
    "        X_train_bigram = ngram_topk(X_train, 2, 300)\n",
    "        features.append(X_train_bigram[0])\n",
    "        feat_dicts_list.append(X_train_bigram[1:-1])\n",
    "    if 'tri' in feats_to_use:\n",
    "        X_train_trigram = ngram_topk(X_train, 3, 200)\n",
    "        features.append(X_train_trigram[0])\n",
    "        feat_dicts_list.append(X_train_trigram[1:-1])\n",
    "    if 'pos' in feats_to_use:\n",
    "        X_train_pos = [pos_tag(tokens) for tokens in X_train]\n",
    "        X_train_pos_unigram = ngram_topk(X_train_pos, 1, 500)\n",
    "        features.append(X_train_pos_unigram[0])\n",
    "        feat_dicts_list.append(X_train_pos_unigram[1:-1])\n",
    "\n",
    "    X_train_feats = np.concatenate( features, axis=1 )\n",
    "    \n",
    "    return X_train_feats, feat_dicts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_test(X_test, feat_dicts_list, feats_to_use = ('len', 'uni' ,'bi' ,'tri' ,'pos')):\n",
    "    X_test = [sent.split() for sent in X_test]\n",
    "    features = []\n",
    "    feat_dicts_list_idx = 0\n",
    "    assert len(feat_dicts_list) == len(feats_to_use)\n",
    "    if 'len' in feats_to_use:\n",
    "        X_test_sentlen = np.reshape(np.asarray([len(sent) for sent in X_test], dtype = np.int32),(-1,1))\n",
    "        feat_dicts_list_idx += 1\n",
    "    else:\n",
    "        X_test_sentlen = np.reshape(np.asarray([-1 for sent in X_test], dtype = np.int32),(-1,1))\n",
    "    features.append(X_test_sentlen)\n",
    "    \n",
    "    if 'uni' in feats_to_use:\n",
    "        X_test_unigram = ngram_topk(X_test, 1, 500, feat_dicts_list[feat_dicts_list_idx])\n",
    "        features.append(X_test_unigram[0])\n",
    "        feat_dicts_list_idx += 1\n",
    "    if 'bi' in feats_to_use:\n",
    "        X_test_bigram = ngram_topk(X_test, 2, 300, feat_dicts_list[feat_dicts_list_idx])\n",
    "        features.append(X_test_bigram[0])\n",
    "        feat_dicts_list_idx += 1\n",
    "    if 'tri' in feats_to_use:\n",
    "        X_test_trigram = ngram_topk(X_test, 3, 200, feat_dicts_list[feat_dicts_list_idx])\n",
    "        features.append(X_test_trigram[0])\n",
    "        feat_dicts_list_idx += 1\n",
    "    if 'pos' in feats_to_use:\n",
    "        X_test_pos = [pos_tag(tokens) for tokens in X_test]\n",
    "        X_test_pos_unigram = ngram_topk(X_test_pos, 1, 500, feat_dicts_list[feat_dicts_list_idx])\n",
    "        features.append(X_test_pos_unigram[0])\n",
    "        feat_dicts_list_idx += 1\n",
    "    \n",
    "    assert len(feat_dicts_list) == feat_dicts_list_idx\n",
    "    X_test_feats = np.concatenate( features, axis=1 )\n",
    "    return X_test_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_feats, feat_dicts_list = get_features_train(X_train, feats_to_use = ('len', 'uni' ,'bi' ,'tri' ,'pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_feats = get_features_test(X_test, feat_dicts_list, feats_to_use = ('len', 'uni' ,'bi' ,'tri' ,'pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESC': 0, 'LOC': 1, 'NUM': 2, 'ABBR': 3, 'ENTY': 4, 'HUM': 5}\n"
     ]
    }
   ],
   "source": [
    "label2idx = {lab: i for i, lab in enumerate(set(Y_train))}\n",
    "idx2label = {i: lab for lab, i in label2idx.items()}\n",
    "print(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_idx = np.asarray([label2idx[lab] for lab in Y_train], dtype=np.int32)\n",
    "Y_test_idx = np.asarray([label2idx[lab] for lab in Y_test], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sublists(input_list):\n",
    "#     subs = []\n",
    "\n",
    "#     for i in range(0, len(input_list) + 1):\n",
    "#         temp = [list(x) for x in combinations(input_list, i)]\n",
    "\n",
    "#         if len(temp) > 0:\n",
    "#             subs.extend(temp)\n",
    "\n",
    "#     return subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Needs Work\n",
    "# def tester(X, Y, iterations = 1):\n",
    "#     kf = KFold(n_splits = 10, shuffle = True)\n",
    "#     scores = []\n",
    "#     mean_scores = []\n",
    "\n",
    "#     for i in range(iterations):\n",
    "#         for train_index, test_index in kf.split(X):\n",
    "#             train_length = len(train_index)\n",
    "#             valid_index = train_index[: train_length // 10]\n",
    "#             train_index = train_index[train_length // 10 :]\n",
    "#             X_train, X_test = X.iloc[train_index].drop(['index'], axis = 1),\n",
    "#                               X.iloc[test_index].drop(['index'], axis = 1)\n",
    "#             Y_train, Y_test = Y.iloc[train_index].drop(['index'], axis = 1),\n",
    "#                               Y.iloc[test_index].drop(['index'], axis = 1)\n",
    "#             clf = linear_model.LogisticRegression(solver = 'liblinear', penalty = 'l2',\n",
    "#                   max_iter = 200).fit(X_train, Y_train.values.ravel())\n",
    "#             scores.append(clf.score(X_test, Y_test))\n",
    "\n",
    "#         mean_scores.append(np.mean(scores))\n",
    "\n",
    "#     return np.mean(mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Needs Work\n",
    "\n",
    "# power_metrics = sublists(metrics)\n",
    "# max_score = -1\n",
    "\n",
    "# for metric_list in power_metrics:\n",
    "#     if metric_list == []:\n",
    "#         continue\n",
    "\n",
    "#     X = data[metric_list].reset_index()\n",
    "#     Y = data['Diabetic'].reset_index()\n",
    "#     score = tester(X, Y, 1, False)\n",
    "\n",
    "#     if score > max_score:\n",
    "#         max_score = score\n",
    "#         print(metric_list)\n",
    "#         print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    cnt = 0\n",
    "    def __init__(self, ):\n",
    "        self.leaf = False\n",
    "        self.majority_class = None\n",
    "        self.attribute_index = None\n",
    "        self.children = dict() # key: attribute_value, value: child_node\n",
    "        self.sent_len_split_val = None # Used at inference time, if attribute_index is 0\n",
    "        self.id = Node.cnt\n",
    "        Node.cnt+=1\n",
    "    \n",
    "    def __str__(self,):\n",
    "        return 'ID: {}  isLeaf: {} majority: {} split_idx: {} split_val = {}'.format(self.id, \n",
    "                                                                                    self.leaf, \n",
    "                                                                                    self.majority_class, \n",
    "                                                                                    self.attribute_index, \n",
    "                                                                                    list(self.children.keys())\n",
    "                                                                                   )\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def traverse_print(self,):\n",
    "        print(self)\n",
    "        for _, child in self.children:\n",
    "              child.traverse_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    \n",
    "    # score has to be from 'entropy', 'gini', 'misclassification'\n",
    "    def __init__(self, score='entropy'):\n",
    "        score_functions = {'entropy': (DecisionTree.compute_entropy, DecisionTree.get_gain_entropy),\n",
    "           'gini': (DecisionTree.compute_gini, DecisionTree.get_gain_gini),\n",
    "           'misclassification': (DecisionTree.compute_misclassification, DecisionTree.get_gain_misclassification)}\n",
    "        \n",
    "        self.root = None\n",
    "        assert score in score_functions.keys()\n",
    "        self.score = score\n",
    "        self.compute_score = score_functions[score][0]\n",
    "        self.get_gain = score_functions[score][1]\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_entropy(labels):\n",
    "        entropy = 0.0\n",
    "        totSamples = len(labels)\n",
    "        labelSet = set(labels.reshape(-1))\n",
    "        for label in labelSet:\n",
    "            prob = np.sum(labels == label) / totSamples\n",
    "            if prob > 1e-12:\n",
    "                entropy -= np.log(prob) * prob\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_gain_entropy(parent_info, data_i, labels):\n",
    "        attr_split_info = 0\n",
    "        attr_count = dict()\n",
    "        for attr_val in set(data_i.reshape(-1)):\n",
    "            ids = np.where(data_i == attr_val)[0]\n",
    "            attr_count[attr_val] = len(ids)\n",
    "            attr_split_info += attr_count[attr_val] * DecisionTree.compute_entropy(labels[ids])\n",
    "        attr_gain = parent_info - attr_split_info\n",
    "        attr_gain_ratio = DecisionTree.compute_dict_entropy(attr_count) * attr_gain\n",
    "        return attr_gain, attr_gain_ratio, attr_count.keys()\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_dict_entropy(attr_count):\n",
    "        entropy = 0\n",
    "        totSamples = sum(attr_count.values())\n",
    "       \n",
    "        labelSet = attr_count.keys()\n",
    "        for label in labelSet:\n",
    "            prob = attr_count[label] / totSamples\n",
    "            if prob > 1e-12:\n",
    "                entropy -= np.log(prob) * prob\n",
    "        return entropy\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_gini(labels):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_gain_gini(parent_info, data_i, labels):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_misclassification(labels):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_gain_misclassification(parent_info, data_i, labels):\n",
    "        pass\n",
    "    \n",
    "    def split_node(self, parent, data, labels, used_attr_index):\n",
    "        num_instances = data.shape[0]\n",
    "        parent_info = self.compute_score(labels) * num_instances\n",
    "        parent.majority_class = Counter(labels.reshape(-1)).most_common(1)[0][0]\n",
    "        \n",
    "        if parent_info == 0 :\n",
    "            parent.leaf = True\n",
    "        \n",
    "        best_attr_index = None\n",
    "        best_info_gain = -float('inf')\n",
    "        best_gain_ratio = -float('inf')\n",
    "        best_attr_keys = None\n",
    "#         sent length case special\n",
    "#         attr_split_info = 0\n",
    "#         attr_count = dict()\n",
    "        sent_len_split_val = stats.mode(data[:, 0])[0][0]\n",
    "        le_ids = np.where(data[:, 0] <= sent_len_split_val)[0]\n",
    "        gt_ids = np.where(data[:, 0] > sent_len_split_val)[0]\n",
    "        data_0 = np.zeros(data.shape[0], dtype=np.int32)\n",
    "        data_0[gt_ids] = 1\n",
    "#         attr_count[0] = le_ids.shape[0]\n",
    "#         attr_count[1] = gt_ids.shape[0]\n",
    "#         attr_split_info = (attr_count[0] * self.compute_entropy(labels[le_ids])) + (attr_count[1] * self.compute_entropy(labels[gt_ids]) )    \n",
    "#         attr_gain = parent_info - attr_split_info\n",
    "        attr_gain, attr_gain_ratio, attr_count_keys = self.get_gain(parent_info, data_0, labels)\n",
    "#         attr_gain_ratio = self.compute_dict_entropy(attr_count) * attr_gain\n",
    "        if best_gain_ratio < attr_gain_ratio and  attr_gain_ratio > 0 :\n",
    "                best_attr_index = 0\n",
    "                best_info_gain = attr_gain\n",
    "                best_gain_ratio = attr_gain_ratio\n",
    "                best_attr_keys = attr_count_keys\n",
    "        \n",
    "        # during ablation, sentence length can be initialized to all zeros this will prevent splittiung in sent dimension/.\n",
    "        for i in range(1, data.shape[1]): # starts from 1 as zero is sentence length (always.) .\n",
    "            if i in used_attr_index:\n",
    "                continue\n",
    "            attr_gain, attr_gain_ratio, attr_count_keys = self.get_gain(parent_info, data[:, i], labels)\n",
    "            if best_gain_ratio < attr_gain_ratio:\n",
    "                best_attr_index = i\n",
    "                best_info_gain = attr_gain\n",
    "                best_gain_ratio = attr_gain_ratio\n",
    "                best_attr_keys = attr_count_keys\n",
    "        if best_gain_ratio <= 0 :\n",
    "            parent.leaf = True\n",
    "            return [] # TO Check    \n",
    "        else:\n",
    "            parent.attribute_index =  best_attr_index\n",
    "            parent.children = { i: Node() for i in best_attr_keys}\n",
    "            to_return = []\n",
    "            if best_attr_index != 0:\n",
    "                used_attr_index.append(best_attr_index)\n",
    "                for i in best_attr_keys:\n",
    "                    inds = np.where(data[:, best_attr_index] == i)[0]\n",
    "                    to_return.append( (parent.children[i], data[inds], labels[inds], used_attr_index) )\n",
    "            else:\n",
    "                parent.sent_len_split_val = sent_len_split_val\n",
    "                to_return.append( (parent.children[0], data[le_ids], labels[le_ids], used_attr_index) )\n",
    "                to_return.append( (parent.children[1], data[gt_ids], labels[gt_ids], used_attr_index) )\n",
    "            return to_return\n",
    "    \n",
    "    def build_tree(self, data, labels):\n",
    "        traversal_q = queue.Queue()\n",
    "        root = Node()\n",
    "        traversal_q.put_nowait( (root, data, labels, [] ))\n",
    "        while not traversal_q.empty():\n",
    "            node_to_split = traversal_q.get_nowait()\n",
    "            child_nodes = self.split_node(*node_to_split)\n",
    "            for child in child_nodes:\n",
    "                traversal_q.put_nowait(child)\n",
    "        self.root = root\n",
    "        return root\n",
    "    \n",
    "    def split_infer(self, node, data, data_indices):\n",
    "        if node.leaf:\n",
    "            return (True, data_indices, np.zeros( (data.shape[0]), dtype = np.int32) + node.majority_class)\n",
    "        else:\n",
    "            to_queue = []\n",
    "            if(node.attribute_index == 0):\n",
    "                left_idx = np.where(data[:,0] <= node.sent_len_split_val)[0]\n",
    "                right_idx = np.where(data[:,0] > node.sent_len_split_val)[0]\n",
    "                to_queue.append( (node.children[0], data[left_idx], data_indices[left_idx]) )\n",
    "                to_queue.append( (node.children[1], data[right_idx], data_indices[right_idx]) )\n",
    "                return (False, to_queue)\n",
    "            else:\n",
    "                for i in node.children.keys():\n",
    "                    split_inds = np.where( data[:, node.attribute_index]  == i)[0]\n",
    "                    if len(split_inds) > 0:\n",
    "                        to_queue.append( (node.children[i], data[split_inds], data_indices[split_inds]) )\n",
    "                return (False, to_queue)\n",
    "    \n",
    "    def get_labels(self, data):\n",
    "        root = self.root\n",
    "        data_idx = np.arange(data.shape[0], dtype = np.int32)\n",
    "        labels = np.zeros( (data.shape[0]), dtype = np.int32) + -1\n",
    "        traversal_q = queue.Queue()\n",
    "        traversal_q.put_nowait( (root, data, data_idx ))\n",
    "        while not traversal_q.empty():\n",
    "            node_to_split = traversal_q.get_nowait()\n",
    "            split_return = self.split_infer(*node_to_split)\n",
    "            if split_return[0]:\n",
    "                labels[split_return[1]] = split_return[2]\n",
    "            else:\n",
    "                for child in split_return[1]:\n",
    "                    traversal_q.put_nowait(child)\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize data\n",
    "X_train_feats_bin = deepcopy(X_train_feats)\n",
    "X_train_feats_bin[:, 1:] = (X_train_feats[:, 1:] > 0).astype(np.int32)\n",
    "\n",
    "X_test_feats_bin = deepcopy(X_test_feats)\n",
    "X_test_feats_bin[:, 1:] = (X_test_feats[:, 1:] > 0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTree()\n",
    "root = dtree.build_tree(data=X_train_feats_bin, labels=Y_train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID: 6  isLeaf: False majority: 4 split_idx: 2 split_val = [0, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2847"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Node.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = dtree.get_labels(data=X_test_feats_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(Y_test_idx, y_pred_test):\n",
    "    acc = (y_pred_test == Y_test_idx).mean()\n",
    "    prec, rec, fscore, _ = precision_recall_fscore_support(Y_test_idx, y_pred_test, average='weighted')\n",
    "    return acc, prec, rec, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.784, Prec: 0.7989338031578664, Rec: 0.784, Fscore: 0.7853790197104482\n"
     ]
    }
   ],
   "source": [
    "print('Acc: {}, Prec: {}, Rec: {}, Fscore: {}'.format(*get_scores(Y_test_idx, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8241854510067325, 0.748570809698703, 0.7763632769347054, None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y_test_idx, y_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = {'len', 'uni' ,'bi' ,'tri' ,'pos'}\n",
    "dtree_list = dict()\n",
    "scores_list = dict()\n",
    "\n",
    "for feat_to_drop in all_features:\n",
    "    feats_to_use = frozenset(all_features - {feat_to_drop})\n",
    "    X_train_feats, feat_dicts_list = get_features_train(X_train, feats_to_use = feats_to_use)\n",
    "    X_test_feats = get_features_test(X_test, feat_dicts_list, feats_to_use = feats_to_use)\n",
    "    X_train_feats_bin = deepcopy(X_train_feats)\n",
    "    X_train_feats_bin[:, 1:] = (X_train_feats[:, 1:] > 0).astype(np.int32)\n",
    "    \n",
    "    X_test_feats_bin = deepcopy(X_test_feats)\n",
    "    X_test_feats_bin[:, 1:] = (X_test_feats[:, 1:] > 0).astype(np.int32)\n",
    "    dtree = DecisionTree()\n",
    "    _ = dtree.build_tree(data=X_train_feats_bin, labels=Y_train_idx)\n",
    "    dtree_list[feats_to_use] = dtree\n",
    "    y_pred_test = dtree.get_labels(data=X_test_feats_bin)\n",
    "    all_scores = get_scores(Y_test_idx, y_pred_test)\n",
    "    scores_list[feats_to_use] = all_scores\n",
    "    print('Features: {}, Missing Feature: {}'.format(feats_to_use, feat_to_drop))\n",
    "    print('Acc: {}, Prec: {}, Rec: {}, Fscore: {}'.format(*all_scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_features = {'len', 'uni' ,'bi' ,'tri' ,'pos'}\n",
    "\n",
    "feats_to_use = frozenset(all_features - {'uni', 'bi', 'tri'})\n",
    "X_train_feats, feat_dicts_list = get_features_train(X_train, feats_to_use = feats_to_use)\n",
    "X_test_feats = get_features_test(X_test, feat_dicts_list, feats_to_use = feats_to_use)\n",
    "X_train_feats_bin = deepcopy(X_train_feats)\n",
    "X_train_feats_bin[:, 1:] = (X_train_feats[:, 1:] > 0).astype(np.int32)\n",
    "\n",
    "X_test_feats_bin = deepcopy(X_test_feats)\n",
    "X_test_feats_bin[:, 1:] = (X_test_feats[:, 1:] > 0).astype(np.int32)\n",
    "dtree = DecisionTree()\n",
    "_ = dtree.build_tree(data=X_train_feats_bin, labels=Y_train_idx)\n",
    "dtree_list[feats_to_use] = dtree\n",
    "y_pred_test = dtree.get_labels(data=X_test_feats_bin)\n",
    "all_scores = get_scores(Y_test_idx, y_pred_test)\n",
    "scores_list[feats_to_use] = all_scores\n",
    "print('Features: {}, Missing Feature: {}'.format(feats_to_use, feat_to_drop))\n",
    "print('Acc: {}, Prec: {}, Rec: {}, Fscore: {}'.format(*all_scores))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
